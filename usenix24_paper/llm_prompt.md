# LLM Prompt for Creating a Binary Privacy Classifier

Below prompt was created to textually represent our [expanded privacy taxonomy](https://github.com/google/hark/blob/main/usenix24_paper/Expanded_Privacy_Taxonomy.pdf), where each high level concept was defined using its fine-grained aspects. We also tried to expand on the fine-grained aspects, where necessary, to avoid ambiguity. The prompt further includes instances of a few reviews and their labels as few-shot examples.

This prompt was the best performing one (based on `F1`, `Precision`, `Recall` and `ROC-AUC` metrics) among the different variants we tried. Our experimentation wasn't exhaustive, and there could be other possible prompt variants that may provide better performance.

```
You are a world-leading expert in data labeling.
We want you to label each "Input" text as being related to Privacy. A text is considered to be related to Privacy, if it explicitly mentions any of the subconcepts defined below:
- Data Collection: Data collection is a privacy issue when it relates to collecting personal data from apps and services. If online apps and services collect personal data that is viewed as unneeded or excessive for the functionality of the service, then it is a privacy issue. Other examples of data collection issues that relate to privacy include: when the purpose of data collection is not shared, when the purpose of data collection is poorly explained, when data about a user is collected from external sources other than the direct app or web service they are using, when more data is gathered than the minimum needed for the app functionality, or when forced to link accounts or link different types of personal information.
- Data Sharing: Data sharing is a privacy issue and refers to scenarios when users want sharing controls to manage which friends, family, or social media see their user generated content; user generated content includes photos, videos, calendars, contacts, passwords and files. Users also want data sharing control manage the sharing of user behavior data, such as location or activity tracking, according to their privacy preferences. Negative examples of data sharing issues that relate to privacy include: 1) when users feel forced to share their personal content with more people or services than they would like, or 2) when oversharing happens (such as unintended or accidental sharing)  due to confusion with sharing controls, or 3) when data is shared across multiple apps or services without explicit user consent. Privacy positive examples include 1) when a user is pleased with a privacy control, or 2) pleased about the functionality of a privacy feature.
- Data Deletion: Data deletion is a privacy issue when the user wants to delete data for a privacy reason; this includes deleting data that is considered personal or deleting data the user is afraid is visible by others in cases when they did not consent. If the user is having trouble deleting their personal data because they cannot find the deletion controls then it is a privacy issue. Similarly, if the privacy controls for data deletion do not have the intended affect, then it is a privacy concern.  Personal data that a user might want to delete for privacy reasons includes user generated data (such as files, images, videos, messages, emails and profile data) as well behavior history (such as online searching, youtube watching history, location tracking history, web cookies, and website browsing data).
- Remove Personally Identifiable Information: Removing Personally Identifiable Information (PII) is a privacy issue when a user wants their name, address, phone number, birthdate, personal photo or profile info removed from a public place. It is a privacy issue when users say they want their PII to be private or non-public, or if they feel visibility of this information was something they did not consent to. However it is not a privacy issue when the reason a user wants to remove PII is because it is inaccurate.
- Data Exposure: Data Exposure is a privacy issue when 1) a user does not have direct control over their personal data, and it may be shared with 1st parties, 3rd parties or advertisers; 2) when users do not have fine-grained privacy controls and cannot influence third party sharing on a per session basis; 3)  when users think that exposure of their personal data poses a safety threat; and 4) when users are upset that their personal data has been shared with the public at large. This differs from Data Sharing that typically involves a user explicitly deciding on a per item basis (files, videos, photos) who to share with.
- Data Hiding: When users want to hide their personal data it is a privacy issue. Examples of data hiding that relate to privacy include wanting the needed controls to hide from others data such as name, contacts, photos, videos, personal events, email, messages, notes, playlists, folders, meetings and profile data. Note that data deletion of an account is not considered a data hiding issue. When users ask how to work the controls, without mentioning privacy or hiding personal data, then it is not a privacy issue.
- Location and Tracking: Location tracking refers to technology that tracks the location and movements of people. Because location tracking data is considered private, the following examples are all considered privacy issues: 1) when users write about wanting to delete their location history; 2) when users want control over who sees their location data; 3) want to know who has access to their location data; 4) when users want location tracking to be turned off or feel location controls are not working as expected.
- Surveillance: Digital surveillance that occurs when apps or web services are used for spying or stalking on people is a privacy issue. Digital spying refers to  the continuous or repeated 1) listening to people with the help of technical devices  such as microphones for recording voices, 2) viewing, photographing or videotaping of individuals via cameras or satellites, or 3) collection of a persons location. When such ongoing monitoring data is given to or collected from an unexpected person or agency, it is a privacy problem. Examples include 1) the use of spyware or stalkerware apps, 2) when cameras or microphones are turned on and the user is unaware that they are on, and 3) when such data is shared with governments or public agencies.
- Consent: When users write about giving consent, or authorization, or approval, to an app or web service to collect their personal data it is a privacy issue. Consent is also a privacy issues when users feel they have not had the opportunity to consent to the collection or sharing of their personal data. When users discuss consent in the context of privacy, they may say 1) they were or were not able to give consent easily, or 2) that something happened without having given consent (like they observed data collection or data sharing), or 3) they may discuss an opt-in or opt-out option related to data sharing. When an app or service activates without prompting and a user thinks they did not consent to this activation, then it is a privacy issue.
- Privacy Controls: When a user discusses any aspect of privacy controls then it is a privacy issues. Privacy controls are commonly provided for microphones, cameras, location tracking, and web browsing. Providing additional passwords to manage which friends and family members see user created content such as files, albums, images, videos, emails and chats, is another type of privacy control. Parental controls are used to manage the privacy settings of their children's accounts.  For such privacy controls, users expect to  1) know how to change them, 2) feel they should be easy to use, 3) to understand what the default settings are,  5) to understand how to download one's private data. When a user feels their privacy choices and preferences are not being honored, then it is a privacy issue.
- Anonymity / Identification: When a user discusses using digital apps and web services in an anonymous fashion, without identifying themselves, then it is a privacy issue. Examples include when a user wants to browse anonymously or in incognito mode, seeks to understand if anonymous borrowing really works, what level of anonymity is provided, or if partial data may be collected when browsing anonymously. Users may want to be anonymous so that websites cannot carry out fingerprinting to identify them. Another privacy aspect of anonymity is misattribution - if users discuss being mistakenly assumed to be someone else, then a privacy issue has occurred.
- Selling data: When one organization or party sells a users private data to a different organization, it is a privacy issues. 1st party services may sell personal data to 3rd party services for the purposes of advertising. This should require the user's consent.
- Advertising: When personal data is used for advertising, it is a privacy issue. It is a privacy issue when 1) users try turn off ads personalization but nevertheless still fear their online activities are being tracked, as this indicates their privacy preferences are not being honored; 2) users would rather pay to stop ads in order to protect their private data from being used for advertising.  When ads are very personal or closely related to a recent user activity, users can feel spooked that their online behavior is being observed and used.
- Data Security: Data security is a privacy issue when 1) users are concerned about the safety and protection of their data, or 2) if a data breach is discussed. Account hacking and safety are a privacy issue when the user discusses 1) that the effect of hacking was to steal or exposure personally identifying information (PII), or 2) that their account is being used by someone else without consent such as in the case of impersonation or via the use of fake profiles.
- Password Issues: Password issues can sometimes be a privacy issue. One example is when someone writes about wanting password protection as a means to control sharing of personal data, such as files, videos, photos; password protection controls sharing for privacy reasons by only allowing people who have been given the password to see the personal data. Another example is when a user gives someone else (friend, family, colleague) a password and that other person abuses the password to impersonate the user, or take over control of their devices, or reset the original password so the user loses control of their device and account.
- Data Accuracy : Data accuracy is a privacy issue when personal data is inaccurate (such as in an address) or obsolete (no longer valid); these are privacy issues because inaccuracies in personal information can lead to misattribution.
- Safety: Safety issues that occur due to personal data exposure or exploitation
- Privacy Invasion: When a user writes that they feel a violation of their privacy, or that their privacy has been invaded, it is a privacy issue.
- Privacy policies and laws: If a user writes anything about a privacy policy, like where it is or it being hard to understand, then it is a privacy issue. If a user writes anything about privacy laws, or consumer data protection acts, or personal data protection bills, it is a privacy issue. Examples of well known privacy laws and regulations include  GDPR, CCPA, CPRA, COPPA, and HIPPA for privacy legal protection of health data.
- Positive Privacy: Privacy issues can contain positive sentiment. Examples of positive privacy issues include: when users are happy with privacy controls, or data protection, or data deletion controls,  or specific privacy features offered in a product.


A text is NOT related to Privacy:
- If it is discussing a feature or functionality not working as expected, and does not explicitly any of the privacy subconcepts earlier.
- If it is complaining that the app consumes or takes too much data, which could be related to mobile data bandwidth usage.

Texts that are vague and that do not explicitly mention any of the privacy subconcepts should be labeled as 'not-privacy'.

In addition to predicting a 'privacy' or 'not-privacy' label, do share your reasons for the predicted label.

Here are a few examples that explain the task:

Input: This app keeps crashing. I have restarted my phone, re-installed the app. Nothing works. I am so angry.
Answer ('privacy' or 'not-privacy'): not-privacy
Reason: The text pertains to the app not working, and does not relate to any of the privacy subconcepts defined.

Input: I want to hide my transaction history. Why am I not able to hide channels that I don't want to watch.
Answer ('privacy' or 'not-privacy'): privacy
Reason: The text discusses hiding transaction history and channels, which relates to 'Data Exposure' privacy subconcept.

Input: This app does not properly save my data. I have lost a lot of my data. I am so angry.
Answer ('privacy' or 'not-privacy'): not-privacy
Reason: The text pertains to the app not properly saving user's data. It is complaining about the app not working properly,and does not relate to any of the privacy subconcepts defined.

Input: You need a picture of my driver's license to send me targeted advertising.
Answer ('privacy' or 'not-privacy'): privacy
Reason: The text discusses a user complaint about sharing driver's license information, which relates to 'Data Collection' privacy subconcept.

Input: This app is taking too much data.
Answer ('privacy' or 'not-privacy'): not-privacy
Reason: The text pertains to the app taking too much data. As the text is vague, it could be about the app consuming more mobile bandwidth data, and it may not relate to any of the privacy subconcepts defined.

Input: Do not let me log in...
Answer ('privacy' or 'not-privacy'): not-privacy
Reason: The text pertains to user suggesting/requesting the app not to let them log in. As the text is vague, it could be due to a functional issues and is not related to any of the privacy subconcepts defined.

Based on the Privacy definition above, is the below input text related to the concept of Privacy.

Input: {{input}}
Answer ('privacy' or 'not-privacy'):
```
